# BELB Benchmark

Code base to reproduce benchmarking experiments on BELB (Biomedical Entity Linking Benchmark) reported in:

```
@article{10.1093/bioinformatics/btad698,
    author = {Garda, Samuele and Weber-Genzel, Leon and Martin, Robert and Leser, Ulf},
    title = {{BELB}: a {B}iomedical {E}ntity {L}inking {B}enchmark},
    journal = {Bioinformatics},
    pages = {btad698},
    year = {2023},
    month = {11},
    issn = {1367-4811},
    doi = {10.1093/bioinformatics/btad698},
    url = {https://doi.org/10.1093/bioinformatics/btad698},
    eprint = {https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btad698/53483107/btad698.pdf},
}

```

## Setup

We assume you have a working installation of [belb](https://github.com/sg-wbi/belb) in your python environment:

```bash
git clone https://github.com/sg-wbi/belb
cd belb
pip install -e .
```

and other requirements:

```bash
(belb-venv) user $ pip install -r requirements.txt
```

## Models

There are two type of models: rule-based entity-specific and those based on pretrained language models (PLM).

### Rule-based entity-specific

| Entity    |                                                                                          | Status | Note                                   |
| --------- | ---------------------------------------------------------------------------------------- | ------ | -------------------------------------- |
| Gene      | [GNormPlus](https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/gnormplus/)               | ✅     | NER+EL                                 |
| Species   | [Linnaues](https://linnaeus.sourceforge.net/)                                            | ✅     | NER+EL                                 |
| Species   | [SR4GN](https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/sr4gn/)                       | ✅     | NER+EL                                 |
| Species   | [SPECIES](https://species.jensenlab.org/)                                                | ❌     | Compilation fails                      |
| Disease   | [TaggerOne](https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/taggerone/)               | ✅     | NER+EL                                 |
| Chemical  | [BC7T2W](https://github.com/bioinformatics-ua/biocreativeVII_track2)                     | ✅     | Installation fails on Linux. NER+EL    |
| Variant   | [tmVar (v3)](https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/tmvar/)                  | ✅     | NER+EL                                 |
| Cell line | [TaggerOne](https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/taggerone/)               | ❌     | Model not available and training fails |
| UMLS      | [MetaMap](https://www.nlm.nih.gov/research/umls/implementation_resources/metamap.html)   | ✅     | NER+EL                                 |
| UMLS      | [QuickUMLS](https://www.nlm.nih.gov/research/umls/implementation_resources/metamap.html) | ❌     | Installation fails                     |
| UMLS      | [SciSpacy](https://allenai.github.io/scispacy/)                                          | ✅     |                                        |

For each system there is a `run_*.sh` script in the `bin` folder.
The script installs the software in the user-specified directory, runs the tool and collects the output in the `data/results/` directory.

```bash
(belb) user $ chmod +x ./bin/run_gnormplus.sh
(belb) user $ ./bin/run_gnormplus.sh <BELB directory> <tool directory>
```

E.g. to run GNormPlus:

```bash
(belb) user $ chmod +x ./bin/run_gnormplus.sh
(belb) user $ ./bin/run_gnormplus.sh <BELB directory> <tool directory>
```

#### BC7T2W

See instructions in corresponding [README.md](benchmark/bc7t2w/README.md)

#### SciSpacy

```bash
(belb) user $ python -m benchmark.scispacy.scispacy --run output --in_dir test --belb_dir ~/data/belb
```

#### MetaMap

See instructions in corresponding [README.md](benchmark/metamap/README.md)

### PLM-based

- [arboEL](https://github.com/dhdhagar/arboEL)
- [GenBioEL](https://github.com/Yuanhy1997/GenBioEL)
- [BioSyn](https://github.com/dmis-lab/BioSyn)

These type of models require training.
We only provide code to create the input in the requested format and to parse the output generated by each model.
Detailed instructions on how run these models on BELB can be found in the corresponding folders (e.g. `benchmark/arboel`).
